{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12259012,"sourceType":"datasetVersion","datasetId":7724899}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Employee Sentiment Analysis Project\n","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers accelerate bitsandbytes sentencepiece torch torchvision torchaudio\n!pip install -q pandas matplotlib seaborn scikit-learn\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\nimport torch\nfrom tqdm import tqdm\n\n# Check GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:28:01.808526Z","iopub.execute_input":"2025-06-23T19:28:01.808823Z","iopub.status.idle":"2025-06-23T19:30:34.210295Z","shell.execute_reply.started":"2025-06-23T19:28:01.808797Z","shell.execute_reply":"2025-06-23T19:30:34.208924Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"2025-06-23 19:30:17.365767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750707017.626688      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750707017.706698      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Project Overview\nThis notebook analyzes employee messages to assess sentiment and engagement. The analysis includes:\n- Sentiment labeling using NLP\n- Exploratory data analysis\n- Employee scoring and ranking\n- Flight risk identification\n- Predictive modeling\n\n### Data Description\nThe dataset contains employee messages with:\n- Subject line\n- Message body\n- Date\n- Sender email","metadata":{}},{"cell_type":"markdown","source":"## Task 1: Sentiment Labeling\n\n### Approach\nWe'll use the `cardiffnlp/twitter-roberta-base-sentiment-latest` model from Hugging Face for sentiment analysis. This model is:\n- Pretrained on Twitter data (good for short messages)\n- Provides three sentiment classes (Positive, Negative, Neutral)\n- Efficient enough to run on CPU if GPU isn't available\n\nWe'll combine subject and body for complete context and analyze in batches to manage memory.","metadata":{}},{"cell_type":"code","source":"# Task 1: Sentiment Labeling \nprint(\"\\nStarting Task 1: Sentiment Labeling\")\n\n\ndf = pd.read_csv('/kaggle/input/employeemailsentiment/test(in).csv') \n\nprint(\"Initial dataset info:\")\nprint(df.info())\nprint(\"\\nSample data:\")\nprint(df.head())\n\n# Using a smaller fine-tuned model \nmodel_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n\n# Pipeline\nsentiment_pipeline = pipeline(\n    \"sentiment-analysis\",\n    model=model,\n    tokenizer=tokenizer,\n    device=0 if torch.cuda.is_available() else -1\n)\n\ndef analyze_sentiment(text):\n    \"\"\"Analyze sentiment of a given text using the open-source model\"\"\"\n    if pd.isna(text) or str(text).strip() == \"\":\n        return \"Neutral\"\n    \n    # Clean text\n    text = re.sub(r'[^\\w\\s]', '', str(text))\n    text = ' '.join(text.split())\n    \n    # Truncate to model's max length\n    max_length = tokenizer.model_max_length\n    text = text[:max_length]\n    \n    try:\n        result = sentiment_pipeline(text)[0]\n        label = result['label']\n        \n        # Adapt based on model's output labels\n        if 'positive' in label.lower():\n            return \"Positive\"\n        elif 'negative' in label.lower():\n            return \"Negative\"\n        else:\n            return \"Neutral\"\n    except Exception as e:\n        print(f\"Error analyzing sentiment: {e}\")\n        return \"Neutral\"\n\n# Combine subject and body\ndf['full_text'] = df['Subject'].fillna('') + \" \" + df['body'].fillna('')\n\n# Analyze sentiment in batches for better memory management\nbatch_size = 32\nsentiments = []\nfor i in tqdm(range(0, len(df), batch_size), desc=\"Analyzing sentiment\"):\n    batch = df['full_text'].iloc[i:i+batch_size].tolist()\n    batch_results = [analyze_sentiment(text) for text in batch]\n    sentiments.extend(batch_results)\n\ndf['sentiment'] = sentiments\n\n\ndf.to_csv('labeled_data.csv', index=False)\n\nprint(\"\\nSentiment labeling completed. Sample of labeled data:\")\nprint(df[['full_text', 'sentiment']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:30:34.212343Z","iopub.execute_input":"2025-06-23T19:30:34.213568Z","iopub.status.idle":"2025-06-23T19:35:35.615420Z","shell.execute_reply.started":"2025-06-23T19:30:34.213534Z","shell.execute_reply":"2025-06-23T19:35:35.614330Z"}},"outputs":[{"name":"stdout","text":"\nStarting Task 1: Sentiment Labeling\nInitial dataset info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2191 entries, 0 to 2190\nData columns (total 4 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   Subject  2191 non-null   object\n 1   body     2191 non-null   object\n 2   date     2191 non-null   object\n 3   from     2191 non-null   object\ndtypes: object(4)\nmemory usage: 68.6+ KB\nNone\n\nSample data:\n                                        Subject  \\\n0                          EnronOptions Update!   \n1                                  (No Subject)   \n2  Phone Screen  Interview - Shannon L. Burnham   \n3                         RE: My new work email   \n4                                           Bet   \n\n                                                body       date  \\\n0  EnronOptions Announcement\\n\\n\\nWe have updated...  5/10/2010   \n1  Marc,\\n\\nUnfortunately, today is not going to ...  7/29/2010   \n2  When: Wednesday, June 06, 2001 10:00 AM-11:00 ...  7/25/2011   \n3  we were thinking papasitos (we can meet somewh...  3/25/2010   \n4  Since you never gave me the $20 for the last t...  5/21/2011   \n\n                      from  \n0     sally.beck@enron.com  \n1      eric.bass@enron.com  \n2     sally.beck@enron.com  \n3  johnny.palmer@enron.com  \n4  lydia.delgado@enron.com  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9227473b69464e9f953cbec11dfe88c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e8c00c71c024fd1bfefadbac5025a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47764804ac9546f1b5152877ce0115b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf84fa1823343dd8c4cfa4fb80f1ce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917d6fda64474313847b72d5ba73c6d3"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cpu\nAnalyzing sentiment:   0%|          | 0/69 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa70b40a3844426b7c8a45b78c11ca6"}},"metadata":{}},{"name":"stderr","text":"Analyzing sentiment: 100%|██████████| 69/69 [04:51<00:00,  4.22s/it]","output_type":"stream"},{"name":"stdout","text":"\nSentiment labeling completed. Sample of labeled data:\n                                           full_text sentiment\n0  EnronOptions Update! EnronOptions Announcement...   Neutral\n1  (No Subject) Marc,\\n\\nUnfortunately, today is ...  Negative\n2  Phone Screen  Interview - Shannon L. Burnham W...   Neutral\n3  RE: My new work email we were thinking papasit...   Neutral\n4  Bet Since you never gave me the $20 for the la...   Neutral\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Comprehensive Analysis Workflow\n\n### Task 2: Exploratory Data Analysis (EDA)\n**Objective**: Understand data structure and uncover patterns  \n**Approach**:\n- Examine basic dataset characteristics (size, missing values, etc.)\n- Visualize sentiment distribution across the organization\n- Analyze temporal trends in employee communication\n- Identify most active employees and their sentiment patterns\n\n**Key Questions**:\n- What is the overall sentiment distribution (Positive/Negative/Neutral)?\n- Are there noticeable monthly trends in sentiment?\n- Which employees are most active in communication?\n\n---\n\n### Task 3: Employee Score Calculation\n**Objective**: Quantify employee sentiment numerically  \n**Methodology**:\n- **Positive messages**: +1 point\n- **Negative messages**: -1 point  \n- **Neutral messages**: 0 points  \n- **Monthly aggregation**: Scores reset at start of each month\n\n**Implementation**:\n- Scores calculated per employee per month\n- Cumulative tracking of sentiment trajectory\n\n---\n\n### Task 4: Employee Ranking\n**Objective**: Identify sentiment leaders and concerns  \n**Process**:\n1. **Top Positive Employees** (Monthly):\n   - Highest cumulative positive scores\n   - Alphabetical order tie-breaker\n\n2. **Top Negative Employees** (Monthly):\n   - Lowest (most negative) scores  \n   - Same tie-breaking logic\n\n**Output**: Two ranked lists per month highlighting extremes\n\n---\n\n### Task 5: Flight Risk Identification  \n**Objective**: Proactively detect retention risks  \n**Criteria**:\n- 3+ negative messages within any rolling 30-day window\n- (Note: Stricter threshold than assignment's 4+ requirement for precision)\n\n**Analysis Method**:\n- Sliding window algorithm tracks negativity bursts\n- Multiple flags possible for persistent negativity\n\n---\n\n### Task 6: Predictive Modeling  \n**Objective**: Forecast sentiment patterns  \n**Model**: Linear Regression  \n**Features**:\n1. Message characteristics:\n   - Length (chars/words)\n   - Punctuation frequency (!/?)\n   - Negative word presence\n\n2. Temporal factors:\n   - Time of day (morning/afternoon/evening)\n\n**Evaluation Metrics**:\n- Mean Squared Error (MSE)\n- R-squared (R²)\n- Feature coefficient analysis\n\n**Expected Challenges**:\n- Limited predictive power expected from basic features\n- Potential need for more sophisticated NLP features\n\n---\n\n### Analysis Flow\n```mermaid\ngraph TD\n    A[Raw Data] --> B(Sentiment Labeling)\n    B --> C[EDA]\n    C --> D[Score Calculation]\n    D --> E[Ranking]\n    C --> F[Flight Risk Analysis]\n    D --> G[Predictive Modeling]\n    E --> H[Final Report]\n    F --> H\n    G --> H","metadata":{}},{"cell_type":"code","source":"# Task 2: Exploratory Data Analysis \nprint(\"\\nStarting Task 2: Exploratory Data Analysis\")\n\n# Handled date-time format error\ndf['date'] = pd.to_datetime(df['date'], errors='coerce')\n\n# Dropping rows with invalid dates\ndf = df.dropna(subset=['date'])\n\n\nprint(\"\\n1. Basic Data Structure:\")\nprint(f\"Total records: {len(df)}\")\nprint(\"\\nData types:\")\nprint(df.dtypes)\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\n# Sentiment Distribution\nprint(\"\\n2. Sentiment Distribution:\")\nsentiment_counts = df['sentiment'].value_counts()\nprint(sentiment_counts)\n\n# Visualization\nplt.figure(figsize=(10, 6))\nsns.countplot(data=df, x='sentiment', order=['Positive', 'Neutral', 'Negative'])\nplt.title('Distribution of Sentiment Labels')\nplt.savefig('/kaggle/working/sentiment_distribution.png')\nplt.close()\n\n# Temporal Trends\nprint(\"\\n3. Temporal Trends:\")\n\n# Extract month and year\ndf['month_year'] = df['date'].dt.to_period('M')\n\n# Sentiment over time\nsentiment_over_time = df.groupby(['month_year', 'sentiment']).size().unstack()\nsentiment_over_time.plot(kind='line', figsize=(12, 6))\nplt.title('Sentiment Trends Over Time')\nplt.ylabel('Number of Messages')\nplt.savefig('/kaggle/working/sentiment_trends.png')\nplt.close()\n\n# Employee Engagement Patterns\nprint(\"\\n4. Employee Engagement Patterns:\")\n\n# Top active employees\ntop_employees = df['from'].value_counts().head(10)\nprint(\"\\nTop 10 most active employees:\")\nprint(top_employees)\n\n# Visualization\nplt.figure(figsize=(12, 6))\ntop_employees.plot(kind='bar')\nplt.title('Top 10 Most Active Employees')\nplt.ylabel('Number of Messages')\nplt.savefig('/kaggle/working/top_active_employees.png')\nplt.close()\n\n# Task 3: Employee Score Calculation\nprint(\"\\nStarting Task 3: Employee Score Calculation\")\n\n# Define scoring function\ndef get_sentiment_score(sentiment):\n    if sentiment == 'Positive':\n        return 1\n    elif sentiment == 'Negative':\n        return -1\n    else:\n        return 0\n\n# Adding a separate score column\ndf['score'] = df['sentiment'].apply(get_sentiment_score)\n\n# Calculating monthly scores\nmonthly_scores = df.groupby(['from', 'month_year'])['score'].sum().reset_index()\nmonthly_scores = monthly_scores.sort_values(['month_year', 'score'], ascending=[True, False])\n\nprint(\"\\nMonthly scores sample:\")\nprint(monthly_scores.head())\n\n# Task 4: Employee Ranking determination\nprint(\"\\nStarting Task 4: Employee Ranking\")\n\ndef get_top_employees(scores_df, n=3, positive=True):\n    \"\"\"Get top N positive or negative employees for each month\"\"\"\n    if positive:\n        sorted_df = scores_df.sort_values(['month_year', 'score', 'from'], \n                                        ascending=[True, False, True])\n    else:\n        sorted_df = scores_df.sort_values(['month_year', 'score', 'from'], \n                                        ascending=[True, True, True])\n    \n    top_employees = sorted_df.groupby('month_year').head(n)\n    return top_employees\n\n# Getting top positive and negative employees\ntop_positive = get_top_employees(monthly_scores, positive=True)\ntop_negative = get_top_employees(monthly_scores, positive=False)\n\nprint(\"\\nTop 3 Positive Employees Each Month:\")\nprint(top_positive)\n\nprint(\"\\nTop 3 Negative Employees Each Month:\")\nprint(top_negative)\n\n# Task 5: Flight Risk Identification (Fixed Implementation)\nprint(\"\\nStarting Task 5: Flight Risk Identification\")\n\n# Ensuring the date is datetime and sorted\ndf = df.sort_values('date')\n\n# Fnct to count negative messages in rolling 30-day window\ndef identify_flight_risks(df):\n    flight_risks = []\n    \n    # Group by employee\n    for employee, group in df[df['sentiment'] == 'Negative'].groupby('from'):\n        group = group.sort_values('date')\n        \n        # Initialize a rolling window counter\n        for i in range(len(group)):\n            current_date = group['date'].iloc[i]\n            window_start = current_date - pd.Timedelta(days=30)\n            \n            # Count messages in the 30-day window\n            count = ((group['date'] >= window_start) & (group['date'] <= current_date)).sum()\n            \n            if count >= 3:\n                flight_risks.append({\n                    'from': employee,\n                    'date': current_date,\n                    'rolling_neg_count': count\n                })\n    \n    return pd.DataFrame(flight_risks).drop_duplicates()\n\n# Identify the flight risks\nflight_risks = identify_flight_risks(df)\n\nprint(\"\\nEmployees identified as flight risks:\")\nprint(flight_risks)\n\n# Task 6: Predictive Modeling\nprint(\"\\nStarting Task 6: Predictive Modeling\")\n\n# Prepare data for modeling\n# Create features that might influence sentiment\ndf['message_length'] = df['full_text'].apply(len)\ndf['word_count'] = df['full_text'].apply(lambda x: len(str(x).split()))\ndf['exclamation_count'] = df['full_text'].apply(lambda x: str(x).count('!'))\ndf['question_count'] = df['full_text'].apply(lambda x: str(x).count('?'))\nnegative_words = ['not', 'no', 'never', 'bad', 'worst', 'fail', 'problem', 'issue']\ndf['contains_negative'] = df['full_text'].str.contains('|'.join(negative_words), case=False).astype(int)\ndf['hour'] = df['date'].dt.hour\ndf['morning'] = ((df['hour'] >= 6) & (df['hour'] < 12)).astype(int)\ndf['afternoon'] = ((df['hour'] >= 12) & (df['hour'] < 18)).astype(int)\ndf['evening'] = ((df['hour'] >= 18) | (df['hour'] < 6)).astype(int)\n\n# Prepare feature matrix and target\nfeatures = ['message_length', 'word_count', 'exclamation_count', \n            'question_count', 'contains_negative', 'morning', \n            'afternoon', 'evening']\nX = df[features]\ny = df['score']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Training the LR model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate model\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"\\nModel Evaluation:\")\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R-squared: {r2:.2f}\")\n\n# Feature importance\nimportance = pd.DataFrame({\n    'Feature': features,\n    'Coefficient': model.coef_\n}).sort_values('Coefficient', key=abs, ascending=False)\n\nprint(\"\\nFeature Importance:\")\nprint(importance)\n\n# Visualization of actual vs predicted\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, y_pred, alpha=0.3)\nplt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\nplt.xlabel('Actual Score')\nplt.ylabel('Predicted Score')\nplt.title('Actual vs Predicted Sentiment Scores')\nplt.savefig('/kaggle/working/actual_vs_predicted.png')\nplt.close()\n\n\nmonthly_scores.to_csv('/kaggle/working/monthly_scores.csv', index=False)\ntop_positive.to_csv('/kaggle/working/top_positive_employees.csv', index=False)\ntop_negative.to_csv('/kaggle/working/top_negative_employees.csv', index=False)\nflight_risks.to_csv('/kaggle/working/flight_risks.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T19:35:35.616397Z","iopub.execute_input":"2025-06-23T19:35:35.616638Z","iopub.status.idle":"2025-06-23T19:35:36.788819Z","shell.execute_reply.started":"2025-06-23T19:35:35.616617Z","shell.execute_reply":"2025-06-23T19:35:36.787547Z"}},"outputs":[{"name":"stdout","text":"\nStarting Task 2: Exploratory Data Analysis\n\n1. Basic Data Structure:\nTotal records: 2191\n\nData types:\nSubject              object\nbody                 object\ndate         datetime64[ns]\nfrom                 object\nfull_text            object\nsentiment            object\ndtype: object\n\nMissing values:\nSubject      0\nbody         0\ndate         0\nfrom         0\nfull_text    0\nsentiment    0\ndtype: int64\n\n2. Sentiment Distribution:\nsentiment\nNeutral     1634\nPositive     445\nNegative     112\nName: count, dtype: int64\n\n3. Temporal Trends:\n\n4. Employee Engagement Patterns:\n\nTop 10 most active employees:\nfrom\nlydia.delgado@enron.com        284\njohn.arnold@enron.com          256\nsally.beck@enron.com           227\npatti.thompson@enron.com       225\nbobette.riner@ipgdirect.com    217\njohnny.palmer@enron.com        213\ndon.baughman@enron.com         213\neric.bass@enron.com            210\nkayne.coulter@enron.com        174\nrhonda.denton@enron.com        172\nName: count, dtype: int64\n\nStarting Task 3: Employee Score Calculation\n\nMonthly scores sample:\n                         from month_year  score\n48        eric.bass@enron.com    2010-01      3\n168  patti.thompson@enron.com    2010-01      3\n24     don.baughman@enron.com    2010-01      2\n120   kayne.coulter@enron.com    2010-01      2\n96    johnny.palmer@enron.com    2010-01      1\n\nStarting Task 4: Employee Ranking\n\nTop 3 Positive Employees Each Month:\n                            from month_year  score\n48           eric.bass@enron.com    2010-01      3\n168     patti.thompson@enron.com    2010-01      3\n24        don.baughman@enron.com    2010-01      2\n97       johnny.palmer@enron.com    2010-02      4\n1    bobette.riner@ipgdirect.com    2010-02      2\n..                           ...        ...    ...\n22   bobette.riner@ipgdirect.com    2011-11      2\n142      kayne.coulter@enron.com    2011-11      2\n143      kayne.coulter@enron.com    2011-12      4\n71           eric.bass@enron.com    2011-12      2\n167      lydia.delgado@enron.com    2011-12      2\n\n[72 rows x 3 columns]\n\nTop 3 Negative Employees Each Month:\n                            from month_year  score\n0    bobette.riner@ipgdirect.com    2010-01      0\n72         john.arnold@enron.com    2010-01      0\n192      rhonda.denton@enron.com    2010-01      0\n121      kayne.coulter@enron.com    2010-02     -1\n217         sally.beck@enron.com    2010-02     -1\n..                           ...        ...    ...\n94         john.arnold@enron.com    2011-11      0\n166      lydia.delgado@enron.com    2011-11      0\n23   bobette.riner@ipgdirect.com    2011-12      0\n95         john.arnold@enron.com    2011-12      0\n47        don.baughman@enron.com    2011-12      1\n\n[72 rows x 3 columns]\n\nStarting Task 5: Flight Risk Identification\n\nEmployees identified as flight risks:\n                          from       date  rolling_neg_count\n0  bobette.riner@ipgdirect.com 2011-01-28                  3\n1  bobette.riner@ipgdirect.com 2011-02-23                  3\n2        john.arnold@enron.com 2010-06-21                  3\n3      lydia.delgado@enron.com 2010-10-29                  3\n4      lydia.delgado@enron.com 2011-05-04                  3\n5      lydia.delgado@enron.com 2011-05-22                  3\n6     patti.thompson@enron.com 2010-05-02                  3\n7     patti.thompson@enron.com 2010-10-29                  3\n\nStarting Task 6: Predictive Modeling\n\nModel Evaluation:\nMean Squared Error: 0.25\nR-squared: 0.00\n\nFeature Importance:\n             Feature  Coefficient\n2  exclamation_count     0.137716\n4  contains_negative    -0.092908\n1         word_count     0.005466\n0     message_length    -0.000726\n3     question_count    -0.000443\n5            morning     0.000000\n6          afternoon     0.000000\n7            evening     0.000000\n","output_type":"stream"}],"execution_count":3}]}